"""
This program extracts data from SpEagle to (Name)Data.txt

The resulting file includes:
Review Feature nodes -> User Feature nodes -> Product Feature nodes
-> Edges between users and reviews* -> Edges between products and reviews*

*: Those parts are generated by User_Review.py for simplicity and
attached at the end of the file manually.

"""

import re
import numpy as np

# Reading data from YelpChi, YelpNYC, and YelpZip ========

# ================Manually change the file name here======
array_yelpchi = np.genfromtxt("YelpZip", dtype=('i'), usecols=(0, 1, 3), defaultfmt="%i")
np.savetxt("ExtractedNYC", array_yelpchi, fmt="%i")

# ========================================================

features = open("ReviewFeatures.txt", "r").read()
# [{('23661', '149'): {'RD': 1.055350553505535, 'ISR': 0, 'EXT': 1, 'ETF': 0, 'DEV': 0},
# ('23815', '124'): {'RD': 0.10164569215876096, 'ISR': 1, 'EXT': 0, 'ETF': 1, 'DEV': 0}}]
user_prodPairs = re.findall(r"(?P<user_prodPair>\('\d+', '\d+'\))", features)

# ========================creating parallel file==========
parallel_file = open("user_product_pairs.txt", "w")
for i in range(len(user_prodPairs)):
    user_prodPairs[i] = user_prodPairs[i].translate(str.maketrans({'(': '', ')': '', ',': '', "'": ''}))
    parallel_file.write(user_prodPairs[i] + "\n")

# ===========Eliminating the zeros========================

RD_features = re.findall(r"('RD': \d\.*\d*)", features)
ISR_features = re.findall(r"('ISR': \d\.*\d*)", features)
EXT_features = re.findall(r"('EXT': \d\.*\d*)", features)
ETF_features = re.findall(r"('ETF': \d\.*\d*)", features)
DEV_features = re.findall(r"('DEV': \d\.*\d*)", features)

# Deleting the features with 0.0
for i in range(len(RD_features)):
    if RD_features[i] == "'RD': 0":
        RD_features[i] = ""
    if ISR_features[i] == "'ISR': 0":
        ISR_features[i] = ""
    if EXT_features[i] == "'EXT': 0":
        EXT_features[i] = ""
    if ETF_features[i] == "'ETF': 0":
        ETF_features[i] = ""
    if DEV_features[i] == "'DEV': 0":
        DEV_features[i] = ""
    RD_features[i] = RD_features[i].replace("'", "")
    ISR_features[i] = ISR_features[i].replace("'", "")
    EXT_features[i] = EXT_features[i].replace("'", "")
    ETF_features[i] = ETF_features[i].replace("'", "")
    DEV_features[i] = DEV_features[i].replace("'", "")

review_dict = { }
y = 0
for x in user_prodPairs:
    review_dict[x] = RD_features[y] + " " + ISR_features[y] \
                     + " " + EXT_features[y] + " " + ETF_features[y] + " " + DEV_features[y]
    y = y + 1

i = 0

# Manually change the destination file name here:
outfile = open("YelpZipData.txt", "w")
num_of_reviews = 0
for line in array_yelpchi:
    while i < len(array_yelpchi):
        tempUser = array_yelpchi.item((i, 0))
        tempProd = array_yelpchi.item((i, 1))
        temp = str(tempUser) + " " + str(tempProd)
        if temp in review_dict:

            if array_yelpchi[i][2] == 1:
                isSpam = 1
            else:
                isSpam = 0
        if temp in review_dict:
            outData = "+" + str(isSpam) + " " + review_dict.get(temp, "")
            outfile.write(outData + "\n")
            num_of_reviews = num_of_reviews + 1
        i = i + 1

# ========================================================
# Appending the user features to the file

user_features = open("UserFeatures.txt", "r").read()
user_ID_long = re.findall(r"'\d+': {'\w+': \d+\.*\d*, '\w+': \d+\.*\d*, '\w+': \d+\.*\d*, "
                          r"'\w+': \d+\.*\d*, '\w+': \d+\.*\d*, '\w+': \d+\.*\d*, '\w+': \d+\.*\d*}", user_features)


# Search for each user in the pair, get the index, and find spammer info by searching the index in review_dict
user_list = [] # a list of users - string
for i in range(len(user_prodPairs)):
    user = re.search(r'\d+', user_prodPairs[i]).group()
    user_list.append(user)

# find the user and record the index
spammer_dict = {i:False for i in range(len(user_ID_long))}
for i in range(array_yelpchi.shape[0]):
    row = array_yelpchi[i,:]
    if row[2] == 1:
        spammer_dict[row[0]] = True

num_of_users = 0
for i in range(len(user_ID_long)):
    num_of_users = num_of_users + 1
    a = user_ID_long[i].split("{")[1][:-1].replace("'","").replace(",","").replace(": ",":")
    if spammer_dict[i] :
        outfile.write("+1 " + a + "\n")
    else:
        outfile.write("+0 " + a + "\n")

# Appending the product features to the file ==================================
prod_features = open("ProdFeatures.txt", "r").read()

prod_ID_long = re.findall(r"'\d+': {'\w+': \d+\.*\d*, '\w+': \d+\.*\d*, '\w+': \d+\.*\d*, "
                          r"'\w+': \d+\.*\d*, '\w+': \d+\.*\d*, '\w+': \d+\.*\d*}", prod_features)

num_of_prod = 0
for i in range(len(prod_ID_long)):
    num_of_prod = num_of_prod + 1
    prod_ID_long[i] = prod_ID_long[i].translate(str.maketrans({'{': '', '}': '', "'": ''}))
    outfile.write("? " + "".join(prod_ID_long[i].split(" ")[1:]) + "\n")

print("Report: " + str(num_of_users) + " users and " + str(num_of_prod)
      + " products and " + str(num_of_reviews) + " reviews. " + "\n")
outfile.close()
parallel_file.close()